import os
#os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = '/home/orangepi/.local/lib/python3.10/site-packages/cv2/qt/plugins'
import sys
import cv2
import time
import librosa
from PyQt5 import QtWidgets, QtGui, QtCore
from PyQt5.QtGui import QMovie
from PyQt5.QtCore import QTimer
from ui_main import Ui_Game
from ultralytics import YOLO
import numpy as np
import pygame
import threading
from threading import Timer
# from pythonosc import udp_client # å¦‚æœä¸éœ€è¦ OSC é€šè¨Šï¼Œå¯ä»¥è¨»è§£æ‰
import matplotlib.pyplot as plt
import random_color # ç¢ºä¿é€™å€‹æ–‡ä»¶å­˜åœ¨ä¸”å…§å®¹æ­£ç¢º

# åˆå§‹åŒ– Pygame æ··éŸ³å™¨
pygame.mixer.init()

# å‡è¨­ logger å·²ç¶“å®šç¾©æˆ–è€…æä¾›ä¸€å€‹ç°¡å–®çš„æ›¿ä»£
class SimpleLogger:
    def info(self, message):
        print(f"[INFO] {message}")
    def error(self, message):
        print(f"[ERROR] {message}")
    def warning(self, message):
        print(f"[WARN] {message}")
logger = SimpleLogger()


class MainApp(QtWidgets.QMainWindow):
    def __init__(self):
        super().__init__()
        self.total_score = 0
        self.prev_time = 0
        self.sound_dict = {}

        self.aa = self.bb = False
        self.temp2 = self.temp3 = 0

        self.fpstemp = []
        self.frame_count = 0
        self.display_fps = 0.0

        self.qt_image = None
        self.reset_fire = True
        self.reset_blue_fire = True

        self.beat = 0.0
        self.beat_times = []
        self.pose_timing = 0
        self.music_start_time = 0.0
        self.beat_interval = 0.0
        self.cool_time = 0.6
        self.combo = 0
        self.combo_mult = 0
        self.ui = Ui_Game()
        self.ui.setupUi(self)

        self.gif = QMovie(r"/home/orangepi/Desktop/Merry_healthy/gifç´ æ/red_fire.gif")
        self.bluegif = QMovie(r"/home/orangepi/Desktop/Merry_healthy/gifç´ æ/blue_fire.gif")

        # --- æ¨¡å‹è¼‰å…¥ (ä½¿ç”¨ YOLOv8 å§¿å‹¢ä¼°è¨ˆæ¨¡å‹) ---
        # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ PyTorch .pt æ¨¡å‹é€²è¡Œæ¼”ç¤ºã€‚
        # å¦‚æœä½ çš„æ¨¡å‹æ˜¯ NCNN æ ¼å¼ï¼Œè«‹ç¢ºä¿å®ƒæ˜¯ç‚ºå§¿å‹¢ä¼°è¨ˆè½‰æ›çš„ NCNN æ¨¡å‹ï¼Œ
        # ä¸¦ä¸” ultralytics åº«æ”¯æ´è¼‰å…¥å’ŒåŸ·è¡Œå®ƒã€‚
        # ä½ çš„åŸå§‹ä»£ç¢¼ä¸­æ˜¯ 'weight/yolo11s-pose_rknn_model'ï¼Œ
        # å¦‚æœé€™æ˜¯ NCNN/RKNN æ¨¡å‹ï¼ŒYOLO é¡åˆ¥å¯èƒ½éœ€è¦é‡å°ç‰¹å®šåŸ·è¡Œæ™‚ç’°å¢ƒï¼ˆä¾‹å¦‚ RKNN Toolkitï¼‰é€²è¡Œé…ç½®ã€‚
        # é€™è£¡ç‚ºäº†ç°¡å–®èµ·è¦‹ï¼Œç›´æ¥ä½¿ç”¨ ultralytics æ”¯æ´çš„ .pt æˆ–å…¶èƒ½è­˜åˆ¥çš„æ¨¡å‹ã€‚
        # å¦‚æœä½ çš„æ¨¡å‹æ˜¯ RKNN æ ¼å¼ä¸” YOLO é¡åˆ¥ç„¡æ³•ç›´æ¥è¼‰å…¥ï¼Œä½ å¯èƒ½éœ€è¦é¡å¤–çš„ RKNN æ¨ç†ä»£ç¢¼ã€‚
        self.model = YOLO("./yolo11n-pose_ncnn_model", task="pose") # å‡è¨­ä½ çš„å§¿å‹¢æ¨¡å‹æ˜¯ .pt æ ¼å¼
        # å¦‚æœæ˜¯ NCNN æ¨¡å‹ï¼Œä¸¦ä¸” ultralytics å¯ä»¥ç›´æ¥è¼‰å…¥ï¼Œå‰‡ä½¿ç”¨ï¼š
        # self.model = YOLO(r'weight/yolo11s-pose_ncnn_model', task="pose")
        logger.info(f"Using device: {self.model.device}")
        # --- End Model Loading ---

        self.video_cap = self.camera_cap = None
        self.lock1 = self.lock2 = self.lock3 = self.lock4 = self.lock5 = True

        self.is_running = False
        self.ui.stopping.setText("stop")

        self.video_timer = QtCore.QTimer()
        self.video_timer.timeout.connect(self.update_video_frame)

        self.camera_timer = QtCore.QTimer()
        self.camera_timer.timeout.connect(self.update_camera_frame)

        self.ui.pushButton.clicked.connect(self.start_all)
        self.ui.stopping.clicked.connect(self.toggle_playback)

        # COCO Keypoint connections (for human pose)
        self.skeleton_connections = [
            (0, 1), (0, 2), (1, 3), (2, 4),      # Head, Neck, Shoulders, Elbows
            (5, 6), (5, 7), (6, 8), (7, 9),      # Shoulders, Hips, Knees, Ankles
            (10, 11), (11, 12), (12, 13), (13, 14), # (Left, Right) Hip, Knee, Ankle
            (5, 11), (6, 12) # For torso connection (left shoulder to left hip, right shoulder to right hip)
        ]
        # Keypoint colors (you can define specific colors for different keypoints)
        self.keypoint_colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0), (0, 255, 255), (255, 255, 0), (255, 0, 255)] * 3


    def calculate_angle(self, a, b, c):  ##è¨ˆç®—é—œç¯€é»è§’åº¦çš„function
        a = np.array(a)  # é ­
        b = np.array(b)  # ä¸­é–“é»
        c = np.array(c)  # å°¾

        radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
        angle = np.abs(radians * 180.0 / np.pi)  # å¾‘è½‰åº¦
        if angle > 180.0:
            angle = 360 - angle
        return angle

    def play_sound(self, choose_sound):
        temp1 = choose_sound
        if temp1 == self.temp2:
            return
        sound_dict = {'1': r'/home/orangepi/Desktop/Merry_healthy/Voice/continue.mp3', '2': r'/home/orangepi/Desktop/Merry_healthy/Voice/A2.mp3',
                      '3': r'/home/orangepi/Desktop/Merry_healthy/Voice/A3.mp3', '4': r'/home/orangepi/Desktop/Merry_healthy/Voice/A4.mp3',
                      '5': r'/home/orangepi/Desktop/Merry_healthy/Voice/A5.mp3',
                      '6': r'/home/orangepi/Desktop/Merry_healthy/Voice/èŸ‹èŸ€V3_é™å™ªæ­£è¦åŒ–_å·¦.wav', '7': r'/home/orangepi/Desktop/Merry_healthy/Voice/èŸ‹èŸ€V3_é™å™ªæ­£è¦åŒ–_å³.wav' }

        pygame.mixer.Sound(sound_dict[choose_sound]).play()
        self.temp2 = choose_sound

    def play_sound_1(self, choose_sound):
        temp1 = choose_sound
        if temp1 == self.temp3:
            return
        sound_dict = {'1': r'/home/orangepi/Desktop/Merry_healthy/Voice/continue.mp3', '2': r'/home/orangepi/Desktop/Merry_healthy/Voice/A2.mp3',
                      '3': r'/home/orangepi/Desktop/Merry_healthy/Voice/A3.mp3', '4': r'/home/orangepi/Desktop/Merry_healthy/Voice/A4.mp3',
                      '5': r'/home/orangepi/Desktop/Merry_healthy/Voice/A5.mp3',
                      '6': r'/home/orangepi/Desktop/Merry_healthy/Voice/èŸ‹èŸ€V3_é™å™ªæ­£è¦åŒ–_å·¦.wav', '7': r'/home/orangepi/Desktop/Merry_healthy/Voice/èŸ‹èŸ€V3_é™å™ªæ­£è¦åŒ–_å³.wav' }

        pygame.mixer.music.load(sound_dict[choose_sound])
        pygame.mixer.music.play()
        self.temp3 = choose_sound

    def play_sound_2(self, choose_sound):
        temp1 = choose_sound
        if temp1 == self.temp3:
            return
        sound_dict = {'1': r'/home/orangepi/Desktop/Merry_healthy/Voice/continue.mp3', '2': r'/home/orangepi/Desktop/Merry_healthy/Voice/A2.mp3',
                      '3': r'/home/orangepi/Desktop/Merry_healthy/Voice/A3.mp3', '4': r'/home/orangepi/Desktop/Merry_healthy/Voice/A4.mp3',
                      '5': r'/home/orangepi/Desktop/Merry_healthy/Voice/A5.mp3',
                      '6': r'/home/orangepi/Desktop/Merry_healthy/Voice/èŸ‹èŸ€V3_é™å™ªæ­£è¦åŒ–_å·¦.wav', '7': r'/home/orangepi/Desktop/Merry_healthy/Voice/èŸ‹èŸ€V3_é™å™ªæ­£è¦åŒ–_å³.wav' }
        pygame.mixer.Sound(sound_dict[choose_sound]).play()
        self.temp3 = choose_sound

    def stop_sound(self):      #çµ‚æ­¢æŒçºŒéŸ³æ•ˆçš„function(å‹•ä½œä¸€)
        pygame.mixer.music.stop()
        self.temp3 = None
    def wait(self,num):
        # time.sleep(0.2)
        self.play_sound_2(num)
    def start_score_timer(self):
        self.score_timer = QtCore.QTimer()
        self.score_timer.timeout.connect(self.show_score)
        self.score_timer.start(100)  # æ¯ 100 æ¯«ç§’æ›´æ–°ä¸€æ¬¡ï¼ˆå¯ä¾éœ€æ±‚èª¿æ•´ï¼‰

    def show_score(self):
        self.ui.label_title.setText(f"Score: {float(self.total_score)}")
    def play_music(self, music_path):       ##æ’­æ”¾èƒŒæ™¯éŸ³æ¨‚çš„function
        y, sr = librosa.load(music_path)
        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
        self.beat_times = librosa.frames_to_time(beats, sr=sr)  ##å…ˆç­‰librosaè™•ç†å®Œå†é–‹å§‹æ’­æ­Œ
        self.beat_interval = self.beat_times[10] - self.beat_times[9]  ##è¨ˆç®—æ‹å­é–“éš”
        pygame.mixer.music.load(music_path)
        pygame.mixer.music.play()

        threading.Thread(target=self.play_beat_in_background, args=(self.beat_times,), daemon=True).start()


    def play_beat_in_background(self, beat_times):
        self.music_start_time = time.time()
        beat_count = 0
        for i, self.beat in enumerate(beat_times):
            if i % 2 != 0:
                continue  # æ¯å…©æ‹ä¸€æ¬¡

            wait_time = self.beat - (time.time() - self.music_start_time)
            if wait_time > 0:  ##ç­‰åˆ°æ‹é»
                time.sleep(wait_time)
            beat_count = (beat_count % 4) + 1  # æ‹é»1~4
            dots = "ğŸ”´  " * beat_count
            self.ui.label_beat.setText(dots)
            self.ui.label_combo.setText(f"Combo âœ–{self.combo}")
            if abs(self.beat - self.pose_timing) > self.beat_interval * 0.9 :  ##å¦‚æœæ²’åšå‹•ä½œ
                self.combo = 0
                self.ui.label_combo.setText(f"Combo âœ–{self.combo}")
            if self.combo < 3:    ####åˆ†æ•¸comboåŠ æˆ
                self.bluegif.stop()
                self.ui.label_fire.clear()

    def start_all(self):
        # pipeline = "v4l2src device=/dev/video0 ! videoconvert ! appsink" # Ubuntu GStreamer pipeline
        # For general webcam, use index 0 or 1 etc.
        self.video_cap = cv2.VideoCapture(r"/home/orangepi/Desktop/Merry_healthy/test (1).mp4")
        music_path = r"/home/orangepi/Desktop/Merry_healthy/song_low.mp3"
        threading.Thread(target=self.play_music, args=(music_path,), daemon=True).start() # ç¢ºä¿éŸ³æ¨‚åœ¨ç¨ç«‹ç·šç¨‹ä¸­æ’­æ”¾
        
        # å˜—è©¦ä½¿ç”¨ GStreamer pipelineï¼Œå¦‚æœä¸è¡Œå‰‡ fallback åˆ°é è¨­
        try:
            self.camera_cap = cv2.VideoCapture("v4l2src device=/dev/video0 ! videoconvert ! appsink", cv2.CAP_GSTREAMER)
            if not self.camera_cap.isOpened():
                raise IOError("GStreamer failed, trying default camera.")
        except IOError:
            logger.warning("GStreamer camera capture failed, falling back to default OpenCV capture.")
            self.camera_cap = cv2.VideoCapture(0) # For webcam (usually index 0)

        # self.camera_cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
        # self.camera_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
        # self.camera_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
        # self.camera_cap.set(cv2.CAP_PROP_FPS, 35)
        self.start_score_timer()
        self.video_timer.start(33)
        self.camera_timer.start(20)
        self.is_running = True
        self.ui.stopping.setText("stop")

    def toggle_playback(self):
        self.is_running = not self.is_running
        self.ui.stopping.setText("stop" if self.is_running else "continue")

    def update_video_frame(self):
        if not self.is_running or self.video_cap is None:
            return
        ret, frame = self.video_cap.read()
        if ret:
            self.display_frame(self.ui.label_left, frame)

    def plot_keypoints_and_skeleton(self, frame, keypoints_data, box_data, conf_scores, class_ids):
        # Draw keypoints and skeleton for each detected person
        for person_idx, kps_xy in enumerate(keypoints_data):
            person_score = conf_scores[person_idx]
            
            # æ ¹æ“š min_conf ç¯©é¸
            min_conf = 0.5 # å‡è¨­ç”¨æ–¼å§¿å‹¢ä¼°è¨ˆçš„æœ€å°ä¿¡å¿ƒåº¦
            if person_score < min_conf:
                continue

            # ç¹ªè£½é‚Šç•Œæ¡†
            x1, y1, x2, y2 = map(int, box_data[person_idx])
            label = self.model.names[int(class_ids[person_idx])] if hasattr(self.model, 'names') else "person"
            color = random_color.get_random_color(label) # ä½¿ç”¨ random_color æ¨¡çµ„

            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2) # rectangle_thickness = 2
            text = f"{label} {person_score:.2f}"
            (w, h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2) # text_thickness = 2
            cv2.rectangle(frame, (x1, y1 - h - 5), (x1 + w, y1), color, -1)
            cv2.putText(frame, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)


            # ç¹ªè£½é—œéµé»
            for kp_idx, (x, y) in enumerate(kps_xy):
                x_int, y_int = int(x), int(y)
                if x_int > 0 and y_int > 0:
                    cv2.circle(frame, (x_int, y_int), 5, self.keypoint_colors[kp_idx % len(self.keypoint_colors)], -1)

            # ç¹ªè£½éª¨æ¶é€£æ¥
            for connection in self.skeleton_connections:
                kp1_idx, kp2_idx = connection
                if kp1_idx < len(kps_xy) and kp2_idx < len(kps_xy):
                    kp1_x, kp1_y = int(kps_xy[kp1_idx][0]), int(kps_xy[kp1_idx][1])
                    kp2_x, kp2_y = int(kps_xy[kp2_idx][0]), int(kps_xy[kp2_idx][1])

                    if kp1_x > 0 and kp1_y > 0 and kp2_x > 0 and kp2_y > 0:
                        cv2.line(frame, (kp1_x, kp1_y), (kp2_x, kp2_y), (0, 255, 255), 2) # é»ƒè‰²ç·šæ¢ï¼Œthickness = 2


    def score_cal(self, dif_time):
        best = self.beat_interval * 0.2  ##æœ€ä½³æ‹é»  1
        nice = self.beat_interval * 0.4  #2
        not_bad = self.beat_interval * 0.8#3
        print(f"Beat Interval: {self.beat_interval:.2f}s, Best: {best:.2f}s, Nice: {nice:.2f}s, Not Bad: {not_bad:.2f}s")

        if self.combo < 5:    ####åˆ†æ•¸comboåŠ æˆ
            self.combo_mult = 1.0
        elif self.combo < 9:
            self.combo_mult = 1.1
        elif self.combo < 13:
            self.combo_mult = 1.25
        else:
            self.combo_mult = 1.5

        if abs(dif_time) < best:           ##bestè·Ÿniceæ‰æœ‰comboåŠ æˆ(self.combo_mult)
            self.total_score += 3 * self.combo_mult
            self.combo += 1
            logger.info("Perfect!")
        elif abs(dif_time) <= nice:
            self.total_score += 2 * self.combo_mult
            self.combo += 1
            logger.info("Good!")
        elif abs(dif_time) <= not_bad:
            self.total_score += 1
            self.combo = 0
            logger.info("OK!")
        else:
            self.combo = 0
            logger.info("Miss!")
        QTimer.singleShot(0, self.update_fire_effect)


    def update_fire_effect(self):
        if self.combo > 5:
            self.ui.label_fire.setMovie(self.gif)
            self.gif.start()
        elif self.combo > 3:
            self.ui.label_fire.setMovie(self.bluegif)
            self.bluegif.start()
        else:
            self.gif.stop()
            self.bluegif.stop()
            self.ui.label_fire.clear()


    def unlock(self, number):    ##è§£æ±ºå‹•ä½œç¶­æŒå°è‡´å¤šæ¬¡èª¤è§¸å•é¡Œçš„function
        if number == '1':
            self.lock1 = True
        elif number == '2':
            self.lock2 = True
        elif number == '3':
            self.lock3 = True
        elif number == '4':
            self.lock4 = True
        elif number == '5':
            self.lock5 = True

    def update_camera_frame(self):
        if not self.is_running or self.camera_cap is None:
            return
        ret, frame = self.camera_cap.read()
        if ret:
            self.frame_count += 1

            if self.frame_count >= 5:        # äº”å¹€æ›´æ–°ä¸€æ¬¡FPS
                curr_time = time.time()
                self.display_fps = self.frame_count / (curr_time - self.prev_time)
                self.prev_time = curr_time
                self.frame_count = 0

            cv2.putText(frame, f"FPS: {self.display_fps:.2f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)

            # --- YOLOv8 å§¿å‹¢ä¼°è¨ˆæ ¸å¿ƒ ---
            results = self.model.predict(source=frame, conf=0.5, classes=0, verbose=False)
            
            keypoints_detected = False
            kpt_data = None # åˆå§‹åŒ– kpt_data
            
            for r in results:
                if hasattr(r, 'keypoints') and r.keypoints is not None:
                    kpt_data = r.keypoints.xy.cpu().numpy() # x, y coordinates for each person
                    conf_scores = r.boxes.conf.cpu().numpy() # Confidence score for each detected person
                    box_data = r.boxes.xyxy.cpu().numpy() # Bounding box for each detected person
                    class_ids = r.boxes.cls.cpu().numpy() # Class ID for each detected person (should be 0 for 'person')
                    
                    self.plot_keypoints_and_skeleton(frame, kpt_data, box_data, conf_scores, class_ids)
                    keypoints_detected = True
                    break # é€šå¸¸æˆ‘å€‘åªè™•ç†ç¬¬ä¸€å€‹æª¢æ¸¬åˆ°çš„äºº
            # --- YOLOv8 å§¿å‹¢ä¼°è¨ˆæ ¸å¿ƒçµæŸ ---
            
            if not keypoints_detected or kpt_data is None or len(kpt_data) == 0:
                self.ui.label_warning.setText("âš ï¸âš ï¸ No person detected or keypoints not found!")
                self.label = False # æ²’æœ‰æª¢æ¸¬åˆ°äººé«”ï¼Œä¸åŸ·è¡Œå‹•ä½œåˆ¤æ–·
            else:
                self.ui.label_warning.setText("")
                self.label = True

                # å‡è¨­åªè™•ç†ç¬¬ä¸€å€‹æª¢æ¸¬åˆ°çš„äºº
                person_keypoints = kpt_data[0] 
                
                # å¾é—œéµé»ä¸­æå–ç‰¹å®šéƒ¨ä½çš„åº§æ¨™
                # é€™è£¡çš„ç´¢å¼•èˆ‡ä½ çš„åŸå§‹ä»£ç¢¼ä¸€è‡´ï¼Œè«‹ç¢ºä¿å®ƒå€‘å°æ‡‰ YOLOv8 çš„é—œéµé»é †åº
                # ä¾‹å¦‚ï¼š0-é¼»å­, 1-å·¦çœ¼, 2-å³çœ¼, 3-å·¦è€³, 4-å³è€³, 5-å·¦è‚©, 6-å³è‚©, 7-å·¦è‚˜, 8-å³è‚˜, 9-å·¦è…•, 10-å³è…•, 11-å·¦è‡€, 12-å³è‡€, 13-å·¦è†, 14-å³è†, 15-å·¦è¸, 16-å³è¸
                
                # ç¢ºä¿æ‰€æœ‰éœ€è¦çš„é—œéµé»éƒ½å­˜åœ¨ä¸”æœ‰æ•ˆ (x, y > 0)
                required_kps_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
                if not all(person_keypoints[idx][0] > 0 and person_keypoints[idx][1] > 0 for idx in required_kps_indices if idx < len(person_keypoints)):
                    self.ui.label_warning.setText("âš ï¸âš ï¸ Some keypoints are not visible!")
                    self.label = False

                if self.label: # å¦‚æœé—œéµé»æœ‰æ•ˆï¼Œå‰‡é€²è¡Œå‹•ä½œåˆ¤æ–·
                    # è¨ˆç®—è§’åº¦
                    right_elbow_angle = self.calculate_angle(
                        person_keypoints[6], person_keypoints[8], person_keypoints[10]
                    )
                    left_elbow_angle = self.calculate_angle(
                        person_keypoints[5], person_keypoints[7], person_keypoints[9]
                    )
                    both_hands_angle = self.calculate_angle(
                        person_keypoints[10], person_keypoints[0], person_keypoints[9]
                    )
                    left_body_angle = self.calculate_angle(
                        person_keypoints[9], person_keypoints[5], person_keypoints[11]
                    )
                    right_body_angle = self.calculate_angle(
                        person_keypoints[10], person_keypoints[6], person_keypoints[12]
                    )
                    left_hand_should_angle = self.calculate_angle(
                        person_keypoints[8], person_keypoints[6], person_keypoints[5]
                    )

                    left_ankle = person_keypoints[15][1]
                    left_knee = person_keypoints[13][1]
                    right_ankle = person_keypoints[16][1]
                    right_knee = person_keypoints[14][1]

                    # å‹•ä½œåˆ¤æ–·é‚è¼¯ (èˆ‡ä½ åŸå§‹ä»£ç¢¼ç›¸åŒ)
                    # å‹•ä½œä¸€(é›™æ‰‹èˆ‰é«˜èˆ‰ç›´)
                    if (person_keypoints[10][1] < (person_keypoints[0][1] - ((person_keypoints[6][1] - person_keypoints[4][1]) / 1.1))) and \
                       (person_keypoints[9][1] < (person_keypoints[0][1] - ((person_keypoints[5][1] - person_keypoints[3][1]) / 1.1))) and self.lock1:
                        self.lock1 = False
                        active_time = time.time() - self.music_start_time
                        self.pose_timing = active_time
                        nearest_beat = min(self.beat_times, key=lambda b: abs(b - active_time))
                        dif_time = active_time - nearest_beat
                        print(f"æˆ‘æ‰“çš„ç¯€å¥{active_time:.2f}s, ç›¸å·®{dif_time:.2f}s, combo:{self.combo}, åŠ æˆ:{self.combo_mult}")
                        t = threading.Thread(target=self.play_sound_1, args=('1',))
                        t.start()
                        tt = threading.Thread(target=self.score_cal, args=(dif_time,))
                        tt.start()
                        cool = threading.Timer(self.cool_time, self.unlock, args=('1',))
                        cool.start()
                    else:
                        if self.temp3 == '1':
                            self.stop_sound()

                    # å‹•ä½œäºŒ(é›™æ‰‹ä½èˆ‰)
                    if (person_keypoints[10][1] < person_keypoints[6][1]) and \
                       (person_keypoints[9][1] < person_keypoints[5][1]) and \
                       (right_elbow_angle < 90) and (left_elbow_angle < 90) and \
                       (left_hand_should_angle > 140) and \
                       (np.abs(person_keypoints[8][0] - person_keypoints[7][0]) > (np.abs(person_keypoints[6][0] - person_keypoints[5][0]) * 2)) and self.lock2:
                        self.lock2 = False
                        active_time = time.time() - self.music_start_time
                        self.pose_timing = active_time
                        nearest_beat = min(self.beat_times, key=lambda b: abs(b - active_time))
                        dif_time = active_time - nearest_beat
                        print(f"æˆ‘æ‰“çš„ç¯€å¥{active_time:.2f}s, ç›¸å·®{dif_time:.2f}s, combo:{self.combo}")
                        a = threading.Thread(target=self.play_sound, args=('2',))
                        a.start()
                        aa = threading.Thread(target=self.score_cal, args=(dif_time,))
                        aa.start()
                        cool = threading.Timer(self.cool_time, self.unlock, args=('2',))
                        cool.start()

                    # å‹•ä½œä¸‰:å³æ‰‹èˆ‰é«˜
                    if (right_elbow_angle > 90) and (person_keypoints[10][1] < person_keypoints[1][1]) and \
                       (person_keypoints[9][1] > person_keypoints[5][1]) and (left_body_angle < 40) and self.lock3:
                        self.lock3 = False
                        active_time = time.time() - self.music_start_time
                        self.pose_timing = active_time
                        nearest_beat = min(self.beat_times, key=lambda b: abs(b - active_time))
                        dif_time = active_time - nearest_beat
                        print(f"æˆ‘æ‰“çš„ç¯€å¥{active_time:.2f}s, ç›¸å·®{dif_time:.2f}s, combo:{self.combo}, åŠ æˆ:{self.combo_mult}")
                        b = threading.Thread(target=self.play_sound, args=('3',))
                        b.start()
                        bb = threading.Thread(target=self.score_cal, args=(dif_time,))
                        bb.start()
                        cool = threading.Timer(self.cool_time, self.unlock, args=('3',))
                        cool.start()

                    # å‹•ä½œå››:å·¦æ‰‹èˆ‰é«˜
                    if (left_elbow_angle > 90) and (person_keypoints[9][1] < person_keypoints[2][1]) and \
                       (person_keypoints[10][1] > person_keypoints[6][1]) and (right_body_angle < 40) and self.lock4:
                        self.lock4 = False
                        active_time = time.time() - self.music_start_time
                        self.pose_timing = active_time
                        nearest_beat = min(self.beat_times, key=lambda b: abs(b - active_time))
                        dif_time = active_time - nearest_beat
                        print(f"æˆ‘æ‰“çš„ç¯€å¥{active_time:.2f}s, ç›¸å·®{dif_time:.2f}s, combo:{self.combo}, åŠ æˆ:{self.combo_mult}")
                        c = threading.Thread(target=self.play_sound, args=('4',))
                        c.start()
                        cc = threading.Thread(target=self.score_cal, args=(dif_time,))
                        cc.start()
                        cool = threading.Timer(self.cool_time, self.unlock, args=('4',))
                        cool.start()

                    # å‹•ä½œäº”:é›™æ‰‹å¼µé–‹
                    if (left_elbow_angle > 110) and (right_elbow_angle > 110) and \
                       (both_hands_angle > 130) and \
                       (right_body_angle > 70) and \
                       (left_body_angle > 70) and \
                       (np.abs(person_keypoints[10][0] - person_keypoints[9][0]) > (np.abs(person_keypoints[6][0] - person_keypoints[5][0]) * 3.2)) and self.lock5:
                        self.lock5 = False
                        active_time = time.time() - self.music_start_time
                        self.pose_timing = active_time
                        nearest_beat = min(self.beat_times, key=lambda b: abs(b - active_time))
                        dif_time = active_time - nearest_beat
                        print(f"æˆ‘æ‰“çš„ç¯€å¥{active_time:.2f}s, ç›¸å·®{dif_time:.2f}s, combo:{self.combo}, åŠ æˆ:{self.combo_mult}")
                        d = threading.Thread(target=self.play_sound, args=('5',))
                        d.start()
                        dd = threading.Thread(target=self.score_cal, args=(dif_time,))
                        dd.start()
                        cool = threading.Timer(self.cool_time, self.unlock, args=('5',))
                        cool.start()

                    # test movements (èŸ‹èŸ€éŸ³æ•ˆ)
                    if (left_ankle < (right_ankle - ((right_ankle - right_knee) / 4))):
                        self.aa = True
                    if self.aa:
                        if (left_ankle > (right_ankle - ((right_ankle - right_knee) / 5))):
                            e = threading.Thread(target=self.wait, args=('6',))
                            e.start()
                            self.aa = False

                    if (right_ankle < (left_ankle - ((left_ankle - left_knee) / 4))):
                        self.bb = True
                    if self.bb:
                        if (right_ankle > (left_ankle - ((left_ankle - left_knee) / 5))):
                            f = threading.Thread(target=self.wait, args=('7',))
                            f.start()
                            self.bb = False

            # æ›´æ–°å½±åƒç•«é¢ (é¡é ­)
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = rgb.shape
            self.qt_image = QtGui.QImage(rgb.data, w, h, ch * w, QtGui.QImage.Format_RGB888)
            self.ui.labelVideo.setPixmap(QtGui.QPixmap.fromImage(self.qt_image))

    def display_frame(self, label, frame):
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb.shape
        qt_image = QtGui.QImage(rgb.data, w, h, ch * w, QtGui.QImage.Format_RGB888)
        label.setPixmap(QtGui.QPixmap.fromImage(qt_image))

    def closeEvent(self, event):
        self.video_timer.stop()
        self.camera_timer.stop()
        if self.video_cap:
            self.video_cap.release()
        if self.camera_cap:
            self.camera_cap.release()
        print(f"ç¸½å¾—åˆ†: {self.total_score:.2f}")
        event.accept()

if __name__ == "__main__":
    try:
        from ultralytics import YOLO
    except ImportError:
        logger.error("Please install the 'ultralytics' package: pip install ultralytics")
        sys.exit(1)

    # ç¢ºä¿ random_color.py åœ¨åŒä¸€å€‹ç›®éŒ„ä¸‹
    # random_color æ¨¡çµ„å…§å®¹æ‡‰é¡ä¼¼æ–¼:
    # import random
    # def get_random_color(label):
    #     random.seed(hash(label)) # ç¢ºä¿ç›¸åŒ label å¾—åˆ°ç›¸åŒé¡è‰²
    #     return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
    try:
        import random_color
    except ImportError:
        logger.error("Please create a 'random_color.py' file with a 'get_random_color' function.")
        sys.exit(1)

    app = QtWidgets.QApplication(sys.argv)
    window = MainApp()
    window.show()
    sys.exit(app.exec_())
